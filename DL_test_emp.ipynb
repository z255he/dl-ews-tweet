{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "441381fd-42d0-4c89-9e70-78bef38e975d",
   "metadata": {},
   "source": [
    "## Code for applying EWS and DL on empirical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93c05af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.ticker as ticker\n",
    "import ewstools\n",
    "from ewstools.models import simulate_ricker\n",
    "import datetime\n",
    "import time\n",
    "from pylab import cm\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963e4951",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91bec86",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs available:\", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c3a757",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_resnet = tf.keras.models.load_model('./trained_models/resnet_300ep_1024batch.h5')\n",
    "model_lstm = tf.keras.models.load_model('./trained_models/lstm_300ep_1024batch.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ffb8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_inputs(df1, df2, n_features=2):\n",
    "    # Ensure df1 and df2 are in the correct shape and convert them to NumPy arrays\n",
    "    arr1 = df1.values.T.reshape(-1, df1.shape[0], 1)  # Shape: (n_samples, n_time_steps, 1)\n",
    "    arr2 = df2.values.T.reshape(-1, df2.shape[0], 1)  # Shape: (n_samples, n_time_steps, 1)\n",
    "    \n",
    "    # Stack the arrays along the last dimension to combine the features\n",
    "    X = np.concatenate((arr1, arr2), axis=2)  # Shape: (n_samples, n_time_steps, n_features)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393eb2de-6c38-4771-b4e7-355edaa2897c",
   "metadata": {},
   "source": [
    "### Obtain EWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1097f32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_count = pd.read_csv('./twitter_data/ca14_count.csv')\n",
    "ny_count = pd.read_csv('./twitter_data/ny18_count.csv')\n",
    "wa_count = pd.read_csv('./twitter_data/wa18_count.csv')\n",
    "bc_count = pd.read_csv('./twitter_data/bc14_count.csv')\n",
    "sg_count = pd.read_csv('./twitter_data/sg_count.csv')\n",
    "mx_count = pd.read_csv('./twitter_data/mx_count.csv')\n",
    "ar_count = pd.read_csv('./twitter_data/ar_count.csv')\n",
    "br_count = pd.read_csv('./twitter_data/br_count.csv')\n",
    "\n",
    "ca_count['Time'] = pd.to_datetime(ca_count['Time'])  # 2011-01-01 to 2015-03-29\n",
    "ny_count['Time'] = pd.to_datetime(ny_count['Time'])  # 2015-05-01 to 2019-05-12\n",
    "wa_count['Time'] = pd.to_datetime(ny_count['Time'])  # 2015-05-01 to 2019-03-15\n",
    "bc_count['Time'] = pd.to_datetime(bc_count['Time'])  # 2010-11-01 to 2014-09-27\n",
    "sg_count['Time'] = pd.to_datetime(sg_count['Time'])  # 2014-01-01 to 2017-12-31\n",
    "mx_count['Time'] = pd.to_datetime(mx_count['Time'])  # 2014-01-01 to 2017-12-31\n",
    "ar_count['Time'] = pd.to_datetime(ar_count['Time'])  # 2014-01-01 to 2017-12-31\n",
    "br_count['Time'] = pd.to_datetime(br_count['Time'])  # 2014-01-01 to 2017-12-31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021a8e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trans denotes the 'index'\n",
    "ts_ca = ewstools.TimeSeries(data=ca_count['Count'], transition=1456)  # first case: 2014-12-27\n",
    "ts_ny = ewstools.TimeSeries(data=ny_count['Count'], transition=1248)  # 2018-09-30\n",
    "ts_wa = ewstools.TimeSeries(data=wa_count['Count'], transition=1338)  # 2018-12-29\n",
    "ts_bc = ewstools.TimeSeries(data=bc_count['Count'], transition=1209)  # 2014-02-22\n",
    "ts_sg = ewstools.TimeSeries(data=sg_count['Count'])\n",
    "ts_mx = ewstools.TimeSeries(data=mx_count['Count'])\n",
    "ts_ar = ewstools.TimeSeries(data=ar_count['Count'])\n",
    "ts_br = ewstools.TimeSeries(data=br_count['Count'])\n",
    "\n",
    "ts_ca.detrend(method='Gaussian', bandwidth=100)\n",
    "ts_ny.detrend(method='Gaussian', bandwidth=100)\n",
    "ts_wa.detrend(method='Gaussian', bandwidth=100)\n",
    "ts_bc.detrend(method='Gaussian', bandwidth=100)\n",
    "ts_sg.detrend(method='Gaussian', bandwidth=100)\n",
    "ts_mx.detrend(method='Gaussian', bandwidth=100)\n",
    "ts_ar.detrend(method='Gaussian', bandwidth=100)\n",
    "ts_br.detrend(method='Gaussian', bandwidth=100)\n",
    "\n",
    "# EWS\n",
    "ts_ca.compute_var(rolling_window=200)\n",
    "ts_ca.compute_auto(rolling_window=200, lag=1)\n",
    "ts_ca.compute_cv(rolling_window=200)\n",
    "ts_ny.compute_var(rolling_window=200)\n",
    "ts_ny.compute_auto(rolling_window=200, lag=1)\n",
    "ts_ny.compute_cv(rolling_window=200)\n",
    "ts_wa.compute_var(rolling_window=200)\n",
    "ts_wa.compute_auto(rolling_window=200, lag=1)\n",
    "ts_wa.compute_cv(rolling_window=200)\n",
    "ts_bc.compute_var(rolling_window=200)\n",
    "ts_bc.compute_auto(rolling_window=200, lag=1)\n",
    "ts_bc.compute_cv(rolling_window=200)\n",
    "ts_sg.compute_var(rolling_window=200)\n",
    "ts_sg.compute_auto(rolling_window=200, lag=1)\n",
    "ts_sg.compute_cv(rolling_window=200)\n",
    "ts_mx.compute_var(rolling_window=200)\n",
    "ts_mx.compute_auto(rolling_window=200, lag=1)\n",
    "ts_mx.compute_cv(rolling_window=200)\n",
    "ts_ar.compute_var(rolling_window=200)\n",
    "ts_ar.compute_auto(rolling_window=200, lag=1)\n",
    "ts_ar.compute_cv(rolling_window=200)\n",
    "ts_br.compute_var(rolling_window=200)\n",
    "ts_br.compute_auto(rolling_window=200, lag=1)\n",
    "ts_br.compute_cv(rolling_window=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a43ca8a-ce1d-48cf-a555-fc97fe656d22",
   "metadata": {},
   "source": [
    "### Obtain DL output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87df600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CA 2014\n",
    "prob_list_ca_resnet = []\n",
    "prob_list_ca_lstm = []\n",
    "\n",
    "trans = 1456\n",
    "end = 0\n",
    "ts_res_ca = ts_ca.state['residuals']/np.mean(np.abs(ts_ca.state['residuals']))\n",
    "while end <= trans:\n",
    "    if end < 500:\n",
    "        prob_list_ca_resnet.append(np.nan)\n",
    "        prob_list_ca_lstm.append(np.nan)\n",
    "    else:\n",
    "        inputs_test = reshape_inputs(ts_res_ca[end-500:end], ts_ca.state['smoothing'][end-500:end])\n",
    "        predict_resnet = model_resnet.predict(inputs_test, verbose=0)\n",
    "        predict_lstm = model_lstm.predict(inputs_test, verbose=0)\n",
    "        prob_list_ca_resnet.append(predict_resnet[0][0])\n",
    "        prob_list_ca_lstm.append(predict_lstm[0][0])\n",
    "    end += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee83b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NY 2018\n",
    "prob_list_ny_resnet = []\n",
    "prob_list_ny_lstm = []\n",
    "\n",
    "trans = 1248\n",
    "end = 0\n",
    "ts_res_ny = ts_ny.state['residuals']/np.mean(np.abs(ts_ny.state['residuals']))\n",
    "while end <= trans:\n",
    "    if end < 500:\n",
    "        prob_list_ny_resnet.append(np.nan)\n",
    "        prob_list_ny_lstm.append(np.nan)\n",
    "    else:\n",
    "        inputs_test = reshape_inputs(ts_res_ny[end-500:end], ts_ny.state['smoothing'][end-500:end])\n",
    "        predict_resnet = model_resnet.predict(inputs_test, verbose=0)\n",
    "        predict_lstm = model_lstm.predict(inputs_test, verbose=0)\n",
    "        prob_list_ny_resnet.append(predict_resnet[0][0])\n",
    "        prob_list_ny_lstm.append(predict_lstm[0][0])\n",
    "    end += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830f9e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WA 2018\n",
    "prob_list_wa_resnet = []\n",
    "prob_list_wa_lstm = []\n",
    "\n",
    "trans = 1338\n",
    "end = 0\n",
    "ts_res_wa = ts_wa.state['residuals']/np.mean(np.abs(ts_wa.state['residuals']))\n",
    "while end <= trans:\n",
    "    if end < 500:\n",
    "        prob_list_wa_resnet.append(np.nan)\n",
    "        prob_list_wa_lstm.append(np.nan)\n",
    "    else:\n",
    "        inputs_test = reshape_inputs(ts_res_wa[end-500:end], ts_wa.state['smoothing'][end-500:end])\n",
    "        predict_resnet = model_resnet.predict(inputs_test, verbose=0)\n",
    "        predict_lstm = model_lstm.predict(inputs_test, verbose=0)\n",
    "        prob_list_wa_resnet.append(predict_resnet[0][0])\n",
    "        prob_list_wa_lstm.append(predict_lstm[0][0])\n",
    "    end += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83af6590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BC 2014\n",
    "prob_list_bc_resnet = []\n",
    "prob_list_bc_lstm = []\n",
    "\n",
    "trans = 1209\n",
    "end = 0\n",
    "ts_res_bc = ts_bc.state['residuals']/np.mean(np.abs(ts_bc.state['residuals']))\n",
    "while end <= trans:\n",
    "    if end < 500:\n",
    "        prob_list_bc_resnet.append(np.nan)\n",
    "        prob_list_bc_lstm.append(np.nan)\n",
    "    else:\n",
    "        inputs_test = reshape_inputs(ts_res_bc[end-500:end], ts_bc.state['smoothing'][end-500:end])\n",
    "        predict_resnet = model_resnet.predict(inputs_test, verbose=0)\n",
    "        predict_lstm = model_lstm.predict(inputs_test, verbose=0)\n",
    "        prob_list_bc_resnet.append(predict_resnet[0][0])\n",
    "        prob_list_bc_lstm.append(predict_lstm[0][0])\n",
    "    end += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b5ade9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SG\n",
    "prob_list_sg_resnet = []\n",
    "prob_list_sg_lstm = []\n",
    "\n",
    "trans = 1461\n",
    "end = 0\n",
    "ts_res_sg = ts_sg.state['residuals']/np.mean(np.abs(ts_sg.state['residuals']))\n",
    "while end <= trans:\n",
    "    if end < 500:\n",
    "        prob_list_sg_resnet.append(np.nan)\n",
    "        prob_list_sg_lstm.append(np.nan)\n",
    "    else:\n",
    "        inputs_test = reshape_inputs(ts_res_sg[end-500:end], ts_sg.state['smoothing'][end-500:end])\n",
    "        predict_resnet = model_resnet.predict(inputs_test, verbose=0)\n",
    "        predict_lstm = model_lstm.predict(inputs_test, verbose=0)\n",
    "        prob_list_sg_resnet.append(predict_resnet[0][0])\n",
    "        prob_list_sg_lstm.append(predict_lstm[0][0])\n",
    "    end += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdc19f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MX\n",
    "prob_list_mx_resnet = []\n",
    "prob_list_mx_lstm = []\n",
    "\n",
    "trans = 1461\n",
    "end = 0\n",
    "ts_res_mx = ts_mx.state['residuals']/np.mean(np.abs(ts_mx.state['residuals']))\n",
    "while end <= trans:\n",
    "    if end < 500:\n",
    "        prob_list_mx_resnet.append(np.nan)\n",
    "        prob_list_mx_lstm.append(np.nan)\n",
    "    else:\n",
    "        inputs_test = reshape_inputs(ts_res_mx[end-500:end], ts_mx.state['smoothing'][end-500:end])\n",
    "        predict_resnet = model_resnet.predict(inputs_test, verbose=0)\n",
    "        predict_lstm = model_lstm.predict(inputs_test, verbose=0)\n",
    "        prob_list_mx_resnet.append(predict_resnet[0][0])\n",
    "        prob_list_mx_lstm.append(predict_lstm[0][0])\n",
    "    end += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bb5eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AR\n",
    "prob_list_ar_resnet = []\n",
    "prob_list_ar_lstm = []\n",
    "\n",
    "trans = 1461\n",
    "end = 0\n",
    "ts_res_ar = ts_ar.state['residuals']/np.mean(np.abs(ts_ar.state['residuals']))\n",
    "while end <= trans:\n",
    "    if end < 500:\n",
    "        prob_list_ar_resnet.append(np.nan)\n",
    "        prob_list_ar_lstm.append(np.nan)\n",
    "    else:\n",
    "        inputs_test = reshape_inputs(ts_res_ar[end-500:end], ts_ar.state['smoothing'][end-500:end])\n",
    "        predict_resnet = model_resnet.predict(inputs_test, verbose=0)\n",
    "        predict_lstm = model_lstm.predict(inputs_test, verbose=0)\n",
    "        prob_list_ar_resnet.append(predict_resnet[0][0])\n",
    "        prob_list_ar_lstm.append(predict_lstm[0][0])\n",
    "    end += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a97f9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BR\n",
    "prob_list_br_resnet = []\n",
    "prob_list_br_lstm = []\n",
    "\n",
    "trans = 1461\n",
    "end = 0\n",
    "ts_res_br = ts_br.state['residuals']/np.mean(np.abs(ts_br.state['residuals']))\n",
    "while end <= trans:\n",
    "    if end < 500:\n",
    "        prob_list_br_resnet.append(np.nan)\n",
    "        prob_list_br_lstm.append(np.nan)\n",
    "    else:\n",
    "        inputs_test = reshape_inputs(ts_res_br[end-500:end], ts_br.state['smoothing'][end-500:end])\n",
    "        predict_resnet = model_resnet.predict(inputs_test, verbose=0)\n",
    "        predict_lstm = model_lstm.predict(inputs_test, verbose=0)\n",
    "        prob_list_br_resnet.append(predict_resnet[0][0])\n",
    "        prob_list_br_lstm.append(predict_lstm[0][0])\n",
    "    end += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d135abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_ca_resnet = pd.DataFrame({'prob':prob_list_ca_resnet})\n",
    "df_test_ca_lstm = pd.DataFrame({'prob':prob_list_ca_lstm})\n",
    "df_test_ny_resnet = pd.DataFrame({'prob':prob_list_ny_resnet})\n",
    "df_test_ny_lstm = pd.DataFrame({'prob':prob_list_ny_lstm})\n",
    "df_test_wa_resnet = pd.DataFrame({'prob':prob_list_wa_resnet})\n",
    "df_test_wa_lstm = pd.DataFrame({'prob':prob_list_wa_lstm})\n",
    "df_test_bc_resnet = pd.DataFrame({'prob':prob_list_bc_resnet})\n",
    "df_test_bc_lstm = pd.DataFrame({'prob':prob_list_bc_lstm})\n",
    "df_test_sg_resnet = pd.DataFrame({'prob':prob_list_sg_resnet})\n",
    "df_test_sg_lstm = pd.DataFrame({'prob':prob_list_sg_lstm})\n",
    "df_test_mx_resnet = pd.DataFrame({'prob':prob_list_mx_resnet})\n",
    "df_test_mx_lstm = pd.DataFrame({'prob':prob_list_mx_lstm})\n",
    "df_test_ar_resnet = pd.DataFrame({'prob':prob_list_ar_resnet})\n",
    "df_test_ar_lstm = pd.DataFrame({'prob':prob_list_ar_lstm})\n",
    "df_test_br_resnet = pd.DataFrame({'prob':prob_list_br_resnet})\n",
    "df_test_br_lstm = pd.DataFrame({'prob':prob_list_br_lstm})\n",
    "\n",
    "ts_test_ca_resnet = ewstools.TimeSeries(data=df_test_ca_resnet['prob'])\n",
    "ts_test_ca_lstm = ewstools.TimeSeries(data=df_test_ca_lstm['prob'])\n",
    "ts_test_ny_resnet = ewstools.TimeSeries(data=df_test_ny_resnet['prob'])\n",
    "ts_test_ny_lstm = ewstools.TimeSeries(data=df_test_ny_lstm['prob'])\n",
    "ts_test_wa_resnet = ewstools.TimeSeries(data=df_test_wa_resnet['prob'])\n",
    "ts_test_wa_lstm = ewstools.TimeSeries(data=df_test_wa_lstm['prob'])\n",
    "ts_test_bc_resnet = ewstools.TimeSeries(data=df_test_bc_resnet['prob'])\n",
    "ts_test_bc_lstm = ewstools.TimeSeries(data=df_test_bc_lstm['prob'])\n",
    "ts_test_sg_resnet = ewstools.TimeSeries(data=df_test_sg_resnet['prob'])\n",
    "ts_test_sg_lstm = ewstools.TimeSeries(data=df_test_sg_lstm['prob'])\n",
    "ts_test_mx_resnet = ewstools.TimeSeries(data=df_test_mx_resnet['prob'])\n",
    "ts_test_mx_lstm = ewstools.TimeSeries(data=df_test_mx_lstm['prob'])\n",
    "ts_test_ar_resnet = ewstools.TimeSeries(data=df_test_ar_resnet['prob'])\n",
    "ts_test_ar_lstm = ewstools.TimeSeries(data=df_test_ar_lstm['prob'])\n",
    "ts_test_br_resnet = ewstools.TimeSeries(data=df_test_br_resnet['prob'])\n",
    "ts_test_br_lstm = ewstools.TimeSeries(data=df_test_br_lstm['prob'])\n",
    "\n",
    "ts_test_ca_resnet.detrend(method='Gaussian', bandwidth=20)\n",
    "ts_test_ca_lstm.detrend(method='Gaussian', bandwidth=20)\n",
    "ts_test_ny_resnet.detrend(method='Gaussian', bandwidth=20)\n",
    "ts_test_ny_lstm.detrend(method='Gaussian', bandwidth=20)\n",
    "ts_test_wa_resnet.detrend(method='Gaussian', bandwidth=20)\n",
    "ts_test_wa_lstm.detrend(method='Gaussian', bandwidth=20)\n",
    "ts_test_bc_resnet.detrend(method='Gaussian', bandwidth=20)\n",
    "ts_test_bc_lstm.detrend(method='Gaussian', bandwidth=20)\n",
    "ts_test_sg_resnet.detrend(method='Gaussian', bandwidth=20)\n",
    "ts_test_sg_lstm.detrend(method='Gaussian', bandwidth=20)\n",
    "ts_test_mx_resnet.detrend(method='Gaussian', bandwidth=20)\n",
    "ts_test_mx_lstm.detrend(method='Gaussian', bandwidth=20)\n",
    "ts_test_ar_resnet.detrend(method='Gaussian', bandwidth=20)\n",
    "ts_test_ar_lstm.detrend(method='Gaussian', bandwidth=20)\n",
    "ts_test_br_resnet.detrend(method='Gaussian', bandwidth=20)\n",
    "ts_test_br_lstm.detrend(method='Gaussian', bandwidth=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc48782-17d9-4ef1-a7f6-c3d62435ecd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2, ax2 = plt.subplots(nrows=4, ncols=4, figsize=(36,20))\n",
    "\n",
    "ax2[0,0].plot(ca_count['Time'], ts_ca.state['state'], linewidth=2, color='xkcd:light periwinkle')\n",
    "ax2[0,0].plot(ca_count['Time'], ts_ca.state['smoothing'], linewidth=3, color='xkcd:dark periwinkle')\n",
    "ax2[0,1].plot(ny_count['Time'], ts_ny.state['state'], linewidth=2, color='xkcd:light periwinkle')\n",
    "ax2[0,1].plot(ny_count['Time'], ts_ny.state['smoothing'], linewidth=3, color='xkcd:dark periwinkle')\n",
    "ax2[0,2].plot(wa_count['Time'], ts_wa.state['state'], linewidth=2, color='xkcd:light periwinkle')\n",
    "ax2[0,2].plot(wa_count['Time'], ts_wa.state['smoothing'], linewidth=3, color='xkcd:dark periwinkle')\n",
    "ax2[0,3].plot(bc_count['Time'], ts_bc.state['state'], linewidth=2, color='xkcd:light periwinkle')\n",
    "ax2[0,3].plot(bc_count['Time'], ts_bc.state['smoothing'], linewidth=3, color='xkcd:dark periwinkle')\n",
    "\n",
    "ax2[0,0].axvline(x=pd.to_datetime('2014-12-27'), linestyle='--', linewidth=2, color='grey')\n",
    "ax2[0,1].axvline(x=pd.to_datetime('2018-09-30'), linestyle='--', linewidth=2, color='grey')\n",
    "ax2[0,2].axvline(x=pd.to_datetime('2018-12-29'), linestyle='--', linewidth=2, color='grey')\n",
    "ax2[0,3].axvline(x=pd.to_datetime('2014-02-22'), linestyle='--', linewidth=2, color='grey')\n",
    "\n",
    "ax2[0,0].text(np.array(ca_count['Time'])[30], 132, 'California, United States', size=30, color='black')\n",
    "ax2[0,1].text(np.array(ny_count['Time'])[30], 132, 'New York, United States', size=30, color='black')\n",
    "ax2[0,2].text(np.array(wa_count['Time'])[30], 132, 'Washington, United States', size=30, color='black')\n",
    "ax2[0,3].text(np.array(bc_count['Time'])[30], 132, 'British Columbia, Canada', size=30, color='black')\n",
    "\n",
    "ax2[0,0].text(pd.to_datetime('2013-12-15'), 153, 'Outbreak', size=28, color='grey')\n",
    "ax2[0,0].annotate('', xy=(np.array(ca_count['Time'])[-1], 1.05), xytext=(pd.to_datetime('2014-12-27'), 1.05), xycoords=('data','axes fraction'), arrowprops=dict(arrowstyle=\"->\"))\n",
    "ax2[0,1].annotate('', xy=(np.array(ny_count['Time'])[-1], 1.05), xytext=(pd.to_datetime('2018-09-30'), 1.05), xycoords=('data','axes fraction'), arrowprops=dict(arrowstyle=\"->\"))\n",
    "ax2[0,2].annotate('', xy=(np.array(wa_count['Time'])[-1], 1.05), xytext=(pd.to_datetime('2018-12-29'), 1.05), xycoords=('data','axes fraction'), arrowprops=dict(arrowstyle=\"->\"))\n",
    "ax2[0,3].annotate('', xy=(np.array(bc_count['Time'])[-1], 1.05), xytext=(pd.to_datetime('2014-02-22'), 1.05), xycoords=('data','axes fraction'), arrowprops=dict(arrowstyle=\"->\"))\n",
    "\n",
    "ax2[1,0].plot(ca_count['Time'], ts_ca.ews['variance'], linewidth=2, color='mediumseagreen', label='Var')\n",
    "ax2[1,0].annotate('', xy=(0, 0.05), xytext=(200/1549, 0.05), arrowprops=dict(arrowstyle=\"<->\"), xycoords='axes fraction')\n",
    "ax2[1,0].axvline(x=pd.to_datetime('2014-12-27'), linestyle='--', linewidth=2, color='grey')\n",
    "\n",
    "ax2[1,1].plot(ny_count['Time'], ts_ny.ews['variance'], linewidth=2, color='mediumseagreen', label='Var')\n",
    "ax2[1,1].annotate('', xy=(0, 0.05), xytext=(200/1473, 0.05), arrowprops=dict(arrowstyle=\"<->\"), xycoords='axes fraction')\n",
    "ax2[1,1].axvline(x=pd.to_datetime('2018-09-30'), linestyle='--', linewidth=2, color='grey')\n",
    "\n",
    "ax2[1,2].plot(wa_count['Time'], ts_wa.ews['variance'], linewidth=2, color='mediumseagreen', label='Var')\n",
    "ax2[1,2].annotate('', xy=(0, 0.05), xytext=(200/1415, 0.05), arrowprops=dict(arrowstyle=\"<->\"), xycoords='axes fraction')\n",
    "ax2[1,2].axvline(x=pd.to_datetime('2018-12-29'), linestyle='--', linewidth=2, color='grey')\n",
    "\n",
    "ax2[1,3].plot(bc_count['Time'], ts_bc.ews['variance'], linewidth=2, color='mediumseagreen', label='Var')\n",
    "ax2[1,3].annotate('', xy=(0, 0.05), xytext=(200/1427, 0.05), arrowprops=dict(arrowstyle=\"<->\"), xycoords='axes fraction')\n",
    "ax2[1,3].axvline(x=pd.to_datetime('2014-02-22'), linestyle='--', linewidth=2, color='grey')\n",
    "\n",
    "ax2[2,0].plot(ca_count['Time'], ts_ca.ews['ac1'], linewidth=2, color='coral', label='AC')\n",
    "ax2[2,0].annotate('', xy=(0, 0.05), xytext=(200/1549, 0.05), arrowprops=dict(arrowstyle=\"<->\"), xycoords='axes fraction')\n",
    "ax2[2,0].axvline(x=pd.to_datetime('2014-12-27'), linestyle='--', linewidth=2, color='grey')\n",
    "\n",
    "ax2[2,1].plot(ny_count['Time'], ts_ny.ews['ac1'], linewidth=2, color='coral', label='AC')\n",
    "ax2[2,1].annotate('', xy=(0, 0.05), xytext=(200/1473, 0.05), arrowprops=dict(arrowstyle=\"<->\"), xycoords='axes fraction')\n",
    "ax2[2,1].axvline(x=pd.to_datetime('2018-09-30'), linestyle='--', linewidth=2, color='grey')\n",
    "\n",
    "ax2[2,2].plot(wa_count['Time'], ts_wa.ews['ac1'], linewidth=2, color='coral', label='AC')\n",
    "ax2[2,2].annotate('', xy=(0, 0.05), xytext=(200/1415, 0.05), arrowprops=dict(arrowstyle=\"<->\"), xycoords='axes fraction')\n",
    "ax2[2,2].axvline(x=pd.to_datetime('2018-12-29'), linestyle='--', linewidth=2, color='grey')\n",
    "\n",
    "ax2[2,3].plot(bc_count['Time'], ts_bc.ews['ac1'], linewidth=2, color='coral', label='AC')\n",
    "ax2[2,3].annotate('', xy=(0, 0.05), xytext=(200/1427, 0.05), arrowprops=dict(arrowstyle=\"<->\"), xycoords='axes fraction')\n",
    "ax2[2,3].axvline(x=pd.to_datetime('2014-02-22'), linestyle='--', linewidth=2, color='grey')\n",
    "\n",
    "ax2[3,0].plot(ts_test_ca_resnet['time'], ts_test_ca_resnet['smoothing'], linewidth=2, color='cornflowerblue', label='ResNet')\n",
    "ax2[3,0].plot(ts_test_ca_resnet['time'], ts_test_ca_lstm['smoothing'], linewidth=2, color='crimson', label='LSTM')\n",
    "ax2[3,0].annotate('', xy=(0, 0.05), xytext=(530/1549, 0.05), arrowprops=dict(arrowstyle=\"<->\"), xycoords='axes fraction')\n",
    "ax2[3,0].text(pd.to_datetime('2013-01-15'), 0.87, 'ResNet', size=28, color='cornflowerblue')\n",
    "ax2[3,0].text(pd.to_datetime('2014-04-01'), 0.87, 'LSTM', size=28, color='crimson')\n",
    "ax2[3,0].axvline(x=pd.to_datetime('2014-12-27'), linestyle='--', linewidth=2, color='grey')\n",
    "\n",
    "ax2[3,1].plot(ts_test_ny_resnet['time'], ts_test_ny_resnet['smoothing'], linewidth=2, color='cornflowerblue', label='ResNet')\n",
    "ax2[3,1].plot(ts_test_ny_resnet['time'], ts_test_ny_lstm['smoothing'], linewidth=2, color='crimson', label='LSTM')\n",
    "ax2[3,1].annotate('', xy=(0, 0.05), xytext=(530/1473, 0.05), arrowprops=dict(arrowstyle=\"<->\"), xycoords='axes fraction')\n",
    "#ax2[3,1].legend(loc='upper left', fontsize=18)\n",
    "ax2[3,1].axvline(x=pd.to_datetime('2018-09-30'), linestyle='--', linewidth=2, color='grey')\n",
    "\n",
    "ax2[3,2].plot(ts_test_wa_resnet['time'], ts_test_wa_resnet['smoothing'], linewidth=2, color='cornflowerblue', label='ResNet')\n",
    "ax2[3,2].plot(ts_test_wa_resnet['time'], ts_test_wa_lstm['smoothing'], linewidth=2, color='crimson', label='LSTM')\n",
    "ax2[3,2].annotate('', xy=(0, 0.05), xytext=(530/1415, 0.05), arrowprops=dict(arrowstyle=\"<->\"), xycoords='axes fraction')\n",
    "ax2[3,2].axvline(x=pd.to_datetime('2018-12-29'), linestyle='--', linewidth=2, color='grey')\n",
    "\n",
    "ax2[3,3].plot(ts_test_bc_resnet['time'], ts_test_bc_resnet['smoothing'], linewidth=2, color='cornflowerblue', label='ResNet')\n",
    "ax2[3,3].plot(ts_test_bc_resnet['time'], ts_test_bc_lstm['smoothing'], linewidth=2, color='crimson', label='LSTM')\n",
    "ax2[3,3].annotate('', xy=(0, 0.05), xytext=(530/1427, 0.05), arrowprops=dict(arrowstyle=\"<->\"), xycoords='axes fraction')\n",
    "ax2[3,3].axvline(x=pd.to_datetime('2014-02-22'), linestyle='--', linewidth=2, color='grey')\n",
    "\n",
    "ax2[0,0].set_xlim(left=np.array(ca_count['Time'])[0], right=np.array(ca_count['Time'])[-1])\n",
    "ax2[1,0].set_xlim(left=np.array(ca_count['Time'])[0], right=np.array(ca_count['Time'])[-1])\n",
    "ax2[2,0].set_xlim(left=np.array(ca_count['Time'])[0], right=np.array(ca_count['Time'])[-1])\n",
    "ax2[3,0].set_xlim(left=np.array(ca_count['Time'])[0], right=np.array(ca_count['Time'])[-1])\n",
    "ax2[0,1].set_xlim(left=np.array(ny_count['Time'])[0], right=np.array(ny_count['Time'])[-1])\n",
    "ax2[1,1].set_xlim(left=np.array(ny_count['Time'])[0], right=np.array(ny_count['Time'])[-1])\n",
    "ax2[2,1].set_xlim(left=np.array(ny_count['Time'])[0], right=np.array(ny_count['Time'])[-1])\n",
    "ax2[3,1].set_xlim(left=np.array(ny_count['Time'])[0], right=np.array(ny_count['Time'])[-1])\n",
    "ax2[0,2].set_xlim(left=np.array(wa_count['Time'])[0], right=np.array(wa_count['Time'])[-1])\n",
    "ax2[1,2].set_xlim(left=np.array(wa_count['Time'])[0], right=np.array(wa_count['Time'])[-1])\n",
    "ax2[2,2].set_xlim(left=np.array(wa_count['Time'])[0], right=np.array(wa_count['Time'])[-1])\n",
    "ax2[3,2].set_xlim(left=np.array(wa_count['Time'])[0], right=np.array(wa_count['Time'])[-1])\n",
    "ax2[0,3].set_xlim(left=np.array(bc_count['Time'])[0], right=np.array(bc_count['Time'])[-1])\n",
    "ax2[1,3].set_xlim(left=np.array(bc_count['Time'])[0], right=np.array(bc_count['Time'])[-1])\n",
    "ax2[2,3].set_xlim(left=np.array(bc_count['Time'])[0], right=np.array(bc_count['Time'])[-1])\n",
    "ax2[3,3].set_xlim(left=np.array(bc_count['Time'])[0], right=np.array(bc_count['Time'])[-1])\n",
    "\n",
    "ax2[0,0].set_ylim(bottom=-3, top=150)\n",
    "ax2[0,1].set_ylim(bottom=-3, top=150)\n",
    "ax2[0,2].set_ylim(bottom=-3, top=150)\n",
    "ax2[0,3].set_ylim(bottom=-3, top=150)\n",
    "ax2[1,0].set_ylim(bottom=-6, top=600)\n",
    "ax2[1,1].set_ylim(bottom=-6, top=600)\n",
    "ax2[1,2].set_ylim(bottom=-6, top=600)\n",
    "ax2[1,3].set_ylim(bottom=-0.6, top=60)\n",
    "ax2[2,0].set_ylim(bottom=-0.2, top=1)\n",
    "ax2[2,1].set_ylim(bottom=-0.2, top=1)\n",
    "ax2[2,2].set_ylim(bottom=-0.2, top=1)\n",
    "ax2[2,3].set_ylim(bottom=-0.2, top=1)\n",
    "ax2[3,0].set_ylim(bottom=-0.05, top=1.05)\n",
    "ax2[3,1].set_ylim(bottom=-0.05, top=1.05)\n",
    "ax2[3,2].set_ylim(bottom=-0.05, top=1.05)\n",
    "ax2[3,3].set_ylim(bottom=-0.05, top=1.05)\n",
    "\n",
    "ax2[3,0].set_xlabel('Time', fontsize=36)\n",
    "ax2[3,1].set_xlabel('Time', fontsize=36)\n",
    "ax2[3,2].set_xlabel('Time', fontsize=36)\n",
    "ax2[3,3].set_xlabel('Time', fontsize=36)\n",
    "ax2[0,0].set_ylabel('Pro-vaccine\\nTweets', fontsize=36)\n",
    "ax2[1,0].set_ylabel('Variance', fontsize=36)\n",
    "ax2[2,0].set_ylabel('Lag-1 AC', fontsize=36)\n",
    "ax2[3,0].set_ylabel('Probability', fontsize=36)\n",
    "\n",
    "for ax in ax2.flatten():\n",
    "    ax.tick_params(axis='both', which='major', labelsize=30)\n",
    "    ax.xaxis.set_major_locator(mdates.YearLocator())\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "\n",
    "ax2[0,0].set_xticklabels([])\n",
    "ax2[0,1].set_xticklabels([])\n",
    "ax2[0,2].set_xticklabels([])\n",
    "ax2[0,3].set_xticklabels([])\n",
    "ax2[1,0].set_xticklabels([])\n",
    "ax2[1,1].set_xticklabels([])\n",
    "ax2[1,2].set_xticklabels([])\n",
    "ax2[1,3].set_xticklabels([])\n",
    "ax2[2,0].set_xticklabels([])\n",
    "ax2[2,1].set_xticklabels([])\n",
    "ax2[2,2].set_xticklabels([])\n",
    "ax2[2,3].set_xticklabels([])\n",
    "\n",
    "ax2[0,0].text(0, 1.05, 'A', transform=ax2[0,0].transAxes, size=40, weight='bold')\n",
    "ax2[0,1].text(0, 1.05, 'B', transform=ax2[0,1].transAxes, size=40, weight='bold')\n",
    "ax2[0,2].text(0, 1.05, 'C', transform=ax2[0,2].transAxes, size=40, weight='bold')\n",
    "ax2[0,3].text(0, 1.05, 'D', transform=ax2[0,3].transAxes, size=40, weight='bold')\n",
    "ax2[1,0].text(0, 1.05, 'E', transform=ax2[1,0].transAxes, size=40, weight='bold')\n",
    "ax2[1,1].text(0, 1.05, 'F', transform=ax2[1,1].transAxes, size=40, weight='bold')\n",
    "ax2[1,2].text(0, 1.05, 'G', transform=ax2[1,2].transAxes, size=40, weight='bold')\n",
    "ax2[1,3].text(0, 1.05, 'H', transform=ax2[1,3].transAxes, size=40, weight='bold')\n",
    "ax2[2,0].text(0, 1.05, 'I', transform=ax2[2,0].transAxes, size=40, weight='bold')\n",
    "ax2[2,1].text(0, 1.05, 'J', transform=ax2[2,1].transAxes, size=40, weight='bold')\n",
    "ax2[2,2].text(0, 1.05, 'K', transform=ax2[2,2].transAxes, size=40, weight='bold')\n",
    "ax2[2,3].text(0, 1.05, 'L', transform=ax2[2,3].transAxes, size=40, weight='bold')\n",
    "ax2[3,0].text(0, 1.05, 'M', transform=ax2[3,0].transAxes, size=40, weight='bold')\n",
    "ax2[3,1].text(0, 1.05, 'N', transform=ax2[3,1].transAxes, size=40, weight='bold')\n",
    "ax2[3,2].text(0, 1.05, 'O', transform=ax2[3,2].transAxes, size=40, weight='bold')\n",
    "ax2[3,3].text(0, 1.05, 'P', transform=ax2[3,3].transAxes, size=40, weight='bold')\n",
    "\n",
    "fig2.tight_layout()\n",
    "plt.savefig('empirical_outbreaks.png', dpi=300)\n",
    "plt.savefig('empirical_outbreaks.eps', format='eps', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e284e82b-4be4-4507-881b-d521e402a190",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2, ax2 = plt.subplots(nrows=4, ncols=4, figsize=(36,20))\n",
    "\n",
    "ax2[0,0].plot(sg_count['Time'], ts_sg.state['state'], linewidth=2, color='xkcd:light periwinkle')\n",
    "ax2[0,0].plot(sg_count['Time'], ts_sg.state['smoothing'], linewidth=3, color='xkcd:dark periwinkle')\n",
    "ax2[0,1].plot(mx_count['Time'], ts_mx.state['state'], linewidth=2, color='xkcd:light periwinkle')\n",
    "ax2[0,1].plot(mx_count['Time'], ts_mx.state['smoothing'], linewidth=3, color='xkcd:dark periwinkle')\n",
    "ax2[0,2].plot(ar_count['Time'], ts_ar.state['state'], linewidth=2, color='xkcd:light periwinkle')\n",
    "ax2[0,2].plot(ar_count['Time'], ts_ar.state['smoothing'], linewidth=3, color='xkcd:dark periwinkle')\n",
    "ax2[0,3].plot(br_count['Time'], ts_br.state['state'], linewidth=2, color='xkcd:light periwinkle')\n",
    "ax2[0,3].plot(br_count['Time'], ts_br.state['smoothing'], linewidth=3, color='xkcd:dark periwinkle')\n",
    "\n",
    "ax2[0,0].text(np.array(sg_count['Time'])[30], 44, 'Singapore', size=30, color='black')\n",
    "ax2[0,1].text(np.array(mx_count['Time'])[30], 44, 'Mexico', size=30, color='black')\n",
    "ax2[0,2].text(np.array(ar_count['Time'])[30], 44, 'Argentina', size=30, color='black')\n",
    "ax2[0,3].text(np.array(br_count['Time'])[30], 44, 'Brazil', size=30, color='black')\n",
    "\n",
    "ax2[1,0].plot(sg_count['Time'], ts_sg.ews['variance'], linewidth=2, color='mediumseagreen', label='Var')\n",
    "ax2[1,0].annotate('', xy=(0, 0.05), xytext=(200/1461, 0.05), arrowprops=dict(arrowstyle=\"<->\"), xycoords='axes fraction')\n",
    "\n",
    "ax2[1,1].plot(mx_count['Time'], ts_mx.ews['variance'], linewidth=2, color='mediumseagreen', label='Var')\n",
    "ax2[1,1].annotate('', xy=(0, 0.05), xytext=(200/1461, 0.05), arrowprops=dict(arrowstyle=\"<->\"), xycoords='axes fraction')\n",
    "\n",
    "ax2[1,2].plot(ar_count['Time'], ts_ar.ews['variance'], linewidth=2, color='mediumseagreen', label='Var')\n",
    "ax2[1,2].annotate('', xy=(0, 0.05), xytext=(200/1461, 0.05), arrowprops=dict(arrowstyle=\"<->\"), xycoords='axes fraction')\n",
    "\n",
    "ax2[1,3].plot(br_count['Time'], ts_br.ews['variance'], linewidth=2, color='mediumseagreen', label='Var')\n",
    "ax2[1,3].annotate('', xy=(0, 0.05), xytext=(200/1461, 0.05), arrowprops=dict(arrowstyle=\"<->\"), xycoords='axes fraction')\n",
    "\n",
    "ax2[2,0].plot(sg_count['Time'], ts_sg.ews['ac1'], linewidth=2, color='coral', label='AC')\n",
    "ax2[2,0].annotate('', xy=(0, 0.05), xytext=(200/1461, 0.05), arrowprops=dict(arrowstyle=\"<->\"), xycoords='axes fraction')\n",
    "\n",
    "ax2[2,1].plot(mx_count['Time'], ts_mx.ews['ac1'], linewidth=2, color='coral', label='AC')\n",
    "ax2[2,1].annotate('', xy=(0, 0.05), xytext=(200/1461, 0.05), arrowprops=dict(arrowstyle=\"<->\"), xycoords='axes fraction')\n",
    "\n",
    "ax2[2,2].plot(ar_count['Time'], ts_ar.ews['ac1'], linewidth=2, color='coral', label='AC')\n",
    "ax2[2,2].annotate('', xy=(0, 0.05), xytext=(200/1461, 0.05), arrowprops=dict(arrowstyle=\"<->\"), xycoords='axes fraction')\n",
    "\n",
    "ax2[2,3].plot(br_count['Time'], ts_br.ews['ac1'], linewidth=2, color='coral', label='AC')\n",
    "ax2[2,3].annotate('', xy=(0, 0.05), xytext=(200/1461, 0.05), arrowprops=dict(arrowstyle=\"<->\"), xycoords='axes fraction')\n",
    "\n",
    "ax2[3,0].plot(ts_test_sg_resnet['time'], ts_test_sg_resnet['smoothing'], linewidth=2, color='cornflowerblue', label='ResNet')\n",
    "ax2[3,0].plot(ts_test_sg_resnet['time'], ts_test_sg_lstm['smoothing'], linewidth=2, color='crimson', label='LSTM')\n",
    "ax2[3,0].annotate('', xy=(0, 0.05), xytext=(530/1461, 0.05), arrowprops=dict(arrowstyle=\"<->\"), xycoords='axes fraction')\n",
    "ax2[3,0].text(pd.to_datetime('2016-06-01'), 0.05, 'ResNet', size=28, color='cornflowerblue')\n",
    "ax2[3,0].text(pd.to_datetime('2017-04-01'), 0.05, 'LSTM', size=28, color='crimson')\n",
    "\n",
    "ax2[3,1].plot(ts_test_mx_resnet['time'], ts_test_mx_resnet['smoothing'], linewidth=2, color='cornflowerblue', label='ResNet')\n",
    "ax2[3,1].plot(ts_test_mx_resnet['time'], ts_test_mx_lstm['smoothing'], linewidth=2, color='crimson', label='LSTM')\n",
    "ax2[3,1].annotate('', xy=(0, 0.05), xytext=(530/1461, 0.05), arrowprops=dict(arrowstyle=\"<->\"), xycoords='axes fraction')\n",
    "\n",
    "ax2[3,2].plot(ts_test_ar_resnet['time'], ts_test_ar_resnet['smoothing'], linewidth=2, color='cornflowerblue', label='ResNet')\n",
    "ax2[3,2].plot(ts_test_ar_resnet['time'], ts_test_ar_lstm['smoothing'], linewidth=2, color='crimson', label='LSTM')\n",
    "ax2[3,2].annotate('', xy=(0, 0.05), xytext=(530/1461, 0.05), arrowprops=dict(arrowstyle=\"<->\"), xycoords='axes fraction')\n",
    "\n",
    "ax2[3,3].plot(ts_test_br_resnet['time'], ts_test_br_resnet['smoothing'], linewidth=2, color='cornflowerblue', label='ResNet')\n",
    "ax2[3,3].plot(ts_test_br_resnet['time'], ts_test_br_lstm['smoothing'], linewidth=2, color='crimson', label='LSTM')\n",
    "ax2[3,3].annotate('', xy=(0, 0.05), xytext=(530/1461, 0.05), arrowprops=dict(arrowstyle=\"<->\"), xycoords='axes fraction')\n",
    "\n",
    "ax2[0,0].set_xlim(left=np.array(sg_count['Time'])[0], right=np.array(sg_count['Time'])[-1])\n",
    "ax2[1,0].set_xlim(left=np.array(sg_count['Time'])[0], right=np.array(sg_count['Time'])[-1])\n",
    "ax2[2,0].set_xlim(left=np.array(sg_count['Time'])[0], right=np.array(sg_count['Time'])[-1])\n",
    "ax2[3,0].set_xlim(left=np.array(sg_count['Time'])[0], right=np.array(sg_count['Time'])[-1])\n",
    "ax2[0,1].set_xlim(left=np.array(mx_count['Time'])[0], right=np.array(mx_count['Time'])[-1])\n",
    "ax2[1,1].set_xlim(left=np.array(mx_count['Time'])[0], right=np.array(mx_count['Time'])[-1])\n",
    "ax2[2,1].set_xlim(left=np.array(mx_count['Time'])[0], right=np.array(mx_count['Time'])[-1])\n",
    "ax2[3,1].set_xlim(left=np.array(mx_count['Time'])[0], right=np.array(mx_count['Time'])[-1])\n",
    "ax2[0,2].set_xlim(left=np.array(ar_count['Time'])[0], right=np.array(ar_count['Time'])[-1])\n",
    "ax2[1,2].set_xlim(left=np.array(ar_count['Time'])[0], right=np.array(ar_count['Time'])[-1])\n",
    "ax2[2,2].set_xlim(left=np.array(ar_count['Time'])[0], right=np.array(ar_count['Time'])[-1])\n",
    "ax2[3,2].set_xlim(left=np.array(ar_count['Time'])[0], right=np.array(ar_count['Time'])[-1])\n",
    "ax2[0,3].set_xlim(left=np.array(br_count['Time'])[0], right=np.array(br_count['Time'])[-1])\n",
    "ax2[1,3].set_xlim(left=np.array(br_count['Time'])[0], right=np.array(br_count['Time'])[-1])\n",
    "ax2[2,3].set_xlim(left=np.array(br_count['Time'])[0], right=np.array(br_count['Time'])[-1])\n",
    "ax2[3,3].set_xlim(left=np.array(br_count['Time'])[0], right=np.array(br_count['Time'])[-1])\n",
    "\n",
    "ax2[0,0].set_ylim(bottom=-1, top=50)\n",
    "ax2[0,1].set_ylim(bottom=-1, top=50)\n",
    "ax2[0,2].set_ylim(bottom=-1, top=50)\n",
    "ax2[0,3].set_ylim(bottom=-1, top=50)\n",
    "ax2[1,0].set_ylim(bottom=-0.4, top=40)\n",
    "ax2[1,1].set_ylim(bottom=-0.4, top=40)\n",
    "ax2[1,2].set_ylim(bottom=-0.4, top=40)\n",
    "ax2[1,3].set_ylim(bottom=-0.4, top=40)\n",
    "ax2[2,0].set_ylim(bottom=-0.2, top=1)\n",
    "ax2[2,1].set_ylim(bottom=-0.2, top=1)\n",
    "ax2[2,2].set_ylim(bottom=-0.2, top=1)\n",
    "ax2[2,3].set_ylim(bottom=-0.2, top=1)\n",
    "ax2[3,0].set_ylim(bottom=-0.05, top=1.05)\n",
    "ax2[3,1].set_ylim(bottom=-0.05, top=1.05)\n",
    "ax2[3,2].set_ylim(bottom=-0.05, top=1.05)\n",
    "ax2[3,3].set_ylim(bottom=-0.05, top=1.05)\n",
    "\n",
    "ax2[3,0].set_xlabel('Time', fontsize=36)\n",
    "ax2[3,1].set_xlabel('Time', fontsize=36)\n",
    "ax2[3,2].set_xlabel('Time', fontsize=36)\n",
    "ax2[3,3].set_xlabel('Time', fontsize=36)\n",
    "ax2[0,0].set_ylabel('Pro-vaccine\\nTweets', fontsize=36)\n",
    "ax2[1,0].set_ylabel('Variance', fontsize=36)\n",
    "ax2[2,0].set_ylabel('Lag-1 AC', fontsize=36)\n",
    "ax2[3,0].set_ylabel('Probability', fontsize=36)\n",
    "\n",
    "for ax in ax2.flatten():\n",
    "    ax.tick_params(axis='both', which='major', labelsize=30)\n",
    "    ax.xaxis.set_major_locator(mdates.YearLocator())\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "\n",
    "ax2[0,0].set_xticklabels([])\n",
    "ax2[0,1].set_xticklabels([])\n",
    "ax2[0,2].set_xticklabels([])\n",
    "ax2[0,3].set_xticklabels([])\n",
    "ax2[1,0].set_xticklabels([])\n",
    "ax2[1,1].set_xticklabels([])\n",
    "ax2[1,2].set_xticklabels([])\n",
    "ax2[1,3].set_xticklabels([])\n",
    "ax2[2,0].set_xticklabels([])\n",
    "ax2[2,1].set_xticklabels([])\n",
    "ax2[2,2].set_xticklabels([])\n",
    "ax2[2,3].set_xticklabels([])\n",
    "\n",
    "ax2[0,0].text(0, 1.05, 'A', transform=ax2[0,0].transAxes, size=40, weight='bold')\n",
    "ax2[0,1].text(0, 1.05, 'B', transform=ax2[0,1].transAxes, size=40, weight='bold')\n",
    "ax2[0,2].text(0, 1.05, 'C', transform=ax2[0,2].transAxes, size=40, weight='bold')\n",
    "ax2[0,3].text(0, 1.05, 'D', transform=ax2[0,3].transAxes, size=40, weight='bold')\n",
    "ax2[1,0].text(0, 1.05, 'E', transform=ax2[1,0].transAxes, size=40, weight='bold')\n",
    "ax2[1,1].text(0, 1.05, 'F', transform=ax2[1,1].transAxes, size=40, weight='bold')\n",
    "ax2[1,2].text(0, 1.05, 'G', transform=ax2[1,2].transAxes, size=40, weight='bold')\n",
    "ax2[1,3].text(0, 1.05, 'H', transform=ax2[1,3].transAxes, size=40, weight='bold')\n",
    "ax2[2,0].text(0, 1.05, 'I', transform=ax2[2,0].transAxes, size=40, weight='bold')\n",
    "ax2[2,1].text(0, 1.05, 'J', transform=ax2[2,1].transAxes, size=40, weight='bold')\n",
    "ax2[2,2].text(0, 1.05, 'K', transform=ax2[2,2].transAxes, size=40, weight='bold')\n",
    "ax2[2,3].text(0, 1.05, 'L', transform=ax2[2,3].transAxes, size=40, weight='bold')\n",
    "ax2[3,0].text(0, 1.05, 'M', transform=ax2[3,0].transAxes, size=40, weight='bold')\n",
    "ax2[3,1].text(0, 1.05, 'N', transform=ax2[3,1].transAxes, size=40, weight='bold')\n",
    "ax2[3,2].text(0, 1.05, 'O', transform=ax2[3,2].transAxes, size=40, weight='bold')\n",
    "ax2[3,3].text(0, 1.05, 'P', transform=ax2[3,3].transAxes, size=40, weight='bold')\n",
    "\n",
    "fig2.tight_layout()\n",
    "plt.savefig('empirical_neutral.png', dpi=300)\n",
    "plt.savefig('empirical_neutral.eps', format='eps', bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
