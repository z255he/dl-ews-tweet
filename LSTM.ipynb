{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5b88f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cffe39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82aae9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data from sde_simulation.ipynb\n",
    "df_res = pd.read_csv('./train_data/train_res.csv')\n",
    "df_sm = pd.read_csv('./train_data/train_sm.csv')\n",
    "df_lb = pd.read_csv('./train_data/train_lb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74f6071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the training set\n",
    "df_res = df_res.sample(frac=1, axis=1, random_state=999)\n",
    "df_sm = df_sm.sample(frac=1, axis=1, random_state=999)\n",
    "df_lb = df_lb.sample(frac=1, random_state=999).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb89587",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps_in, n_steps_out, n_features = 500, 1, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a27750",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_inputs(df1, df2, n_features=2):\n",
    "    # Ensure df1 and df2 are in the correct shape and convert them to NumPy arrays\n",
    "    arr1 = df1.values.T.reshape(-1, df1.shape[0], 1)  # Shape: (n_samples, n_time_steps, 1)\n",
    "    arr2 = df2.values.T.reshape(-1, df2.shape[0], 1)  # Shape: (n_samples, n_time_steps, 1)\n",
    "    \n",
    "    # Stack the arrays along the last dimension to combine the features\n",
    "    X = np.concatenate((arr1, arr2), axis=2)  # Shape: (n_samples, n_time_steps, n_features)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d22fbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = reshape_inputs(df_res, df_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c225b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0546af",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = np.array(df_lb.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13aee75",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f523949",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_size_param = 2\n",
    "learning_rate_param = 0.0005\n",
    "batch_param = 1024\n",
    "dropout_percent = 0.1\n",
    "filters_param = 50\n",
    "mem_cells = 50\n",
    "mem_cells2 = 10\n",
    "kernel_size_param = 12\n",
    "epoch_param = 300\n",
    "initializer_param = 'lecun_normal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e915f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Conv1D(filters=filters_param, kernel_size=kernel_size_param, padding='same', activation='relu', input_shape=(n_steps_in, n_features), kernel_initializer=initializer_param))\n",
    "model.add(tf.keras.layers.Dropout(rate=dropout_percent))\n",
    "model.add(tf.keras.layers.MaxPool1D(pool_size=pool_size_param))\n",
    "model.add(tf.keras.layers.LSTM(mem_cells, return_sequences=True, kernel_initializer=initializer_param))\n",
    "model.add(tf.keras.layers.Dropout(rate=dropout_percent))\n",
    "model.add(tf.keras.layers.LSTM(mem_cells2, kernel_initializer=initializer_param))\n",
    "model.add(tf.keras.layers.Dropout(rate=dropout_percent))\n",
    "model.add(tf.keras.layers.Dense(n_steps_out, activation='sigmoid', kernel_initializer=initializer_param))\n",
    "opt = tf.keras.optimizers.legacy.Adam(learning_rate=learning_rate_param)\n",
    "model.compile(optimizer=opt, loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140ce129",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf82b15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fit model\n",
    "model.fit(inputs, targets, epochs=epoch_param, batch_size=batch_param, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d834762",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./trained_models/lstm_400ep_1024batch_updated4.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
