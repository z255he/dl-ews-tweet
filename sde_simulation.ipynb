{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51a6a88a-0fae-4921-b4d9-7dc60b47d85e",
   "metadata": {},
   "source": [
    "## Code for simulating the SDE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5da0522-a239-4792-9266-90419efca2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import ewstools\n",
    "from ewstools.models import simulate_ricker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcebc454-1121-4e6b-9190-f31c55c13126",
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_init():\n",
    "    # initiate parameters\n",
    "    R0 = np.random.uniform(12, 18)\n",
    "    gamma = np.random.uniform(365/22, 365/13)\n",
    "    mu = np.random.uniform(1/70, 1/50)\n",
    "    kappa = 3000\n",
    "    delta = 3e-4\n",
    "    N = 200000\n",
    "    N1 = N*np.random.uniform(0.05, 0.4)\n",
    "    h = np.random.uniform(0.4, 0.8)\n",
    "    c = np.random.uniform(10, 200)\n",
    "    tau = np.random.uniform(50000, 100000)\n",
    "    post_prob = 0.2\n",
    "    param = {'R0':R0, 'gamma':gamma, 'mu':mu, 'kappa':kappa, 'delta':delta, 'N':N, 'N1':N1, 'h':h, 'c':c,\n",
    "             'tau':tau, 'post_prob':post_prob}\n",
    "    return param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03776193-f0d7-4085-9a18-a9bd7a9ea599",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_plot(I, threshold):\n",
    "    # A plot is valid if the infected proportion is no larger than the threshold\n",
    "    # Abnormal realizations with large infected proportion will be disgarded\n",
    "    return max(I) <= threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439d923c-f48d-4cc8-8782-303ca9dc58d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413db948-719d-4cfb-8336-ecd46241693b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transition(x, thres):\n",
    "    # Return the transition time point, or -1 if no transition occurs\n",
    "    for i in range(len(x)):\n",
    "        if x[i] < thres:\n",
    "            return i\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffd0508-a550-42ba-a901-71b7397c0d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def levy_sde_media(param, ic, sigma, tf, dt):\n",
    "    # param: dict of parameters\n",
    "    # ic: list of initial conditions\n",
    "    # sigma: list of noise amplitudes\n",
    "    # tf: final time\n",
    "    # dt: timestep\n",
    "    \n",
    "    R0 = param['R0']\n",
    "    gamma = param['gamma']\n",
    "    mu = param['mu']\n",
    "    beta = R0*(gamma+mu)\n",
    "    kappa = param['kappa']\n",
    "    delta = param['delta']\n",
    "    N = param['N']\n",
    "    N1 = param['N1']\n",
    "    h = param['h']\n",
    "    c = param['c']\n",
    "    tau = param['tau']\n",
    "    \n",
    "    s, i, x1, x2 = ic[0], ic[1], ic[2], ic[3]\n",
    "    N2 = N - N1\n",
    "    x = (x1*N1 + x2*N2)/N\n",
    "    tw_orig = c*x1*(1-x1) + tau*i\n",
    "    tw = tw_orig\n",
    "    \n",
    "    S, I, X1, X2, X, Tw = [s], [i], [x1], [x2], [x], [tw]\n",
    "    \n",
    "    tot = int(tf/dt)\n",
    "    alpha = 1.5\n",
    "    while True:  # get rid of extremely large noises\n",
    "        r = sp.stats.levy_stable.rvs(alpha=alpha, beta=0, size=tot)\n",
    "        if max(r) < 200 and min(r) > -200:\n",
    "            break\n",
    "\n",
    "    t = 0\n",
    "    j = 1\n",
    "    T = [t]\n",
    "    while j <= tot:\n",
    "        t += dt\n",
    "\n",
    "        # increasing vaccine risk\n",
    "        omega = (t*0.5 + 2)*1e-4\n",
    "\n",
    "        A1 = -omega + i + delta*(2*x1-1 + (1-h)*(2*x2-1))\n",
    "        A2 = -omega + i + delta*(2*x2-1 + (1-h)*(2*x1-1))\n",
    "        A3 = -omega + i + delta*(2-h)*(x1+x2-1)\n",
    "\n",
    "        f_s = mu*(1-x) - beta*np.exp(-0.6*i)*s*i - mu*s\n",
    "        f_i = beta*np.exp(-0.6*i)*s*i - (gamma+mu)*i\n",
    "        f_x1 = kappa*x1*(1-x1)*A1 + (1-h)*kappa*(x2*(1-x1)*max(A3,0) - (1-x2)*x1*max(-A3,0))\n",
    "        f_x2 = kappa*x2*(1-x2)*A2 + (1-h)*kappa*(x1*(1-x2)*max(A3,0) - (1-x1)*x2*max(-A3,0))\n",
    "\n",
    "        dL = r[j-1]\n",
    "\n",
    "        s = min(max(s + f_s*dt + (dt**(1/alpha))*sigma[0]*dL, 0), 1)\n",
    "        i = min(max(i + f_i*dt + (dt**(1/alpha))*sigma[1]*dL, 0), 1)\n",
    "        x1 = min(max(x1 + f_x1*dt + (dt**(1/alpha))*sigma[2]*dL, 0), 1)\n",
    "        x2 = min(max(x2 + f_x2*dt + (dt**(1/alpha))*sigma[3]*dL, 0), 1)\n",
    "        \n",
    "        # N1 and N2 are changing over time\n",
    "        # growth rate of N1 is approx 5% per year\n",
    "        N1 = N1*(1 + 0.05/1000)\n",
    "        N2 = N - N1\n",
    "        x = (x1*N1 + x2*N2)/N\n",
    "\n",
    "        # baseline Tw number\n",
    "        tw_orig = c*x1*(1-x1) + tau*i\n",
    "        \n",
    "        prob = np.random.uniform()\n",
    "        post_prob = 0.2+0.8*sigmoid(Tw[-1]-100)\n",
    "        \n",
    "        k = 0.2\n",
    "        while True:\n",
    "            rt = sp.stats.levy_stable.rvs(alpha=1.2, beta=0.25-1/(tw_orig+4), scale=1+0.2*sigmoid((tw_orig-50)/20), loc=(1-k)*tw_orig)\n",
    "            if rt < min(2*c, 5*tw_orig):\n",
    "                break\n",
    "        tw = max(k*tw_orig+rt,0)\n",
    "        if prob >= post_prob:\n",
    "            tw = sum(np.random.binomial(1, 0.1, int(tw)))\n",
    "\n",
    "        T.append(t)\n",
    "        S.append(s)\n",
    "        I.append(i)\n",
    "        X1.append(x1)\n",
    "        X2.append(x2)\n",
    "        X.append(x)\n",
    "        Tw.append(tw)\n",
    "        \n",
    "        j += 1\n",
    "\n",
    "    return T, S, I, X1, X2, X, Tw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b0032c-1739-4136-a5a4-f2d41f10d192",
   "metadata": {},
   "outputs": [],
   "source": [
    "def levy_sde_media_null(param, ic, sigma, tf, dt):\n",
    "    # ic: list of initial conditions\n",
    "    # tf: final time\n",
    "    # dt: timestep\n",
    "    \n",
    "    R0 = param['R0']\n",
    "    gamma = param['gamma']\n",
    "    mu = param['mu']\n",
    "    beta = R0*(gamma+mu)\n",
    "    kappa = param['kappa']\n",
    "    delta = param['delta']\n",
    "    N = param['N']\n",
    "    N1 = param['N1']\n",
    "    h = param['h']\n",
    "    c = param['c']\n",
    "    tau = param['tau']\n",
    "    \n",
    "    s, i, x1, x2 = ic[0], ic[1], ic[2], ic[3]\n",
    "    N2 = N - N1\n",
    "    x = (x1*N1 + x2*N2)/N\n",
    "    tw_orig = c*x1*(1-x1) + tau*i\n",
    "    tw = tw_orig\n",
    "    \n",
    "    S, I, X1, X2, X, Tw = [s], [i], [x1], [x2], [x], [tw]\n",
    "    \n",
    "    tot = int(tf/dt)\n",
    "    alpha = 1.5\n",
    "    while True:  # get rid of extremely large noises\n",
    "        r = sp.stats.levy_stable.rvs(alpha=alpha, beta=0, size=tot)\n",
    "        if max(r) < 200 and min(r) > -200:\n",
    "            break\n",
    "\n",
    "    t = 0\n",
    "    j = 1\n",
    "    T = [t]\n",
    "    while j <= tot:\n",
    "        t += dt\n",
    "\n",
    "        # constant vaccine risk\n",
    "        omega = np.random.uniform(0.7, 0.9)*delta*(2-h)\n",
    "\n",
    "        A1 = -omega + i + delta*(2*x1-1 + (1-h)*(2*x2-1))\n",
    "        A2 = -omega + i + delta*(2*x2-1 + (1-h)*(2*x1-1))\n",
    "        A3 = -omega + i + delta*(2-h)*(x1+x2-1)\n",
    "\n",
    "        f_s = mu*(1-x) - beta*np.exp(-0.6*i)*s*i - mu*s\n",
    "        f_i = beta*np.exp(-0.6*i)*s*i - (gamma+mu)*i\n",
    "        f_x1 = kappa*x1*(1-x1)*A1 + (1-h)*kappa*(x2*(1-x1)*max(A3,0) - (1-x2)*x1*max(-A3,0))\n",
    "        f_x2 = kappa*x2*(1-x2)*A2 + (1-h)*kappa*(x1*(1-x2)*max(A3,0) - (1-x1)*x2*max(-A3,0))\n",
    "\n",
    "        dL = r[j-1]\n",
    "\n",
    "        s = min(max(s + f_s*dt + (dt**(1/alpha))*sigma[0]*dL, 0), 1)\n",
    "        i = min(max(i + f_i*dt + (dt**(1/alpha))*sigma[1]*dL, 0), 1)\n",
    "        x1 = min(max(x1 + f_x1*dt + (dt**(1/alpha))*sigma[2]*dL, 0), 1)\n",
    "        x2 = min(max(x2 + f_x2*dt + (dt**(1/alpha))*sigma[3]*dL, 0), 1)\n",
    "        \n",
    "        # N1 and N2 are changing over time\n",
    "        # growth rate of N1 is approx 5% per year\n",
    "        N1 = N1*(1 + 0.05/1000)\n",
    "        N2 = N - N1\n",
    "        x = (x1*N1 + x2*N2)/N\n",
    "\n",
    "        tw_orig = c*x1*(1-x1) + tau*i\n",
    "        \n",
    "        prob = np.random.uniform()\n",
    "        post_prob = 0.2+0.8*sigmoid(Tw[-1]-80)\n",
    "        \n",
    "        k = 0.2\n",
    "        while True:\n",
    "            rt = sp.stats.levy_stable.rvs(alpha=1.2, beta=0.25-1/(tw_orig+4), scale=1+0.2*sigmoid((tw_orig-50)/20), loc=(1-k)*tw_orig)\n",
    "            if rt < min(2*c, 5*tw_orig):\n",
    "                break\n",
    "        tw = max(k*tw_orig+rt,0)\n",
    "        if prob >= post_prob:\n",
    "            tw = sum(np.random.binomial(1, 0.1, int(tw)))\n",
    "\n",
    "        T.append(t)\n",
    "        S.append(s)\n",
    "        I.append(i)\n",
    "        X1.append(x1)\n",
    "        X2.append(x2)\n",
    "        X.append(x)\n",
    "        Tw.append(tw)\n",
    "        \n",
    "        j += 1\n",
    "\n",
    "    return T, S, I, X1, X2, X, Tw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d760c6d1-9406-489f-b140-ea57573dd4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positive samples\n",
    "# For the convenience of demonstration, we run a relatively small number of simulations\n",
    "# The training set contains 10000 positive samples\n",
    "num_simu_1 = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148c3c22-85b0-47f3-9a30-0f781b3b0081",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_s = pd.DataFrame()\n",
    "df_i = pd.DataFrame()\n",
    "df_x1 = pd.DataFrame()\n",
    "df_x2 = pd.DataFrame()\n",
    "df_x = pd.DataFrame()\n",
    "df_tw = pd.DataFrame()\n",
    "thres_list = []\n",
    "trans_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f48d3e6-474b-43d7-9534-79aa2b6d5fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "while i < num_simu_1:\n",
    "    check = False\n",
    "    param = param_init()\n",
    "    while not(check):\n",
    "        T, S, I, X1, X2, X, Tw = levy_sde_media(param, [0.01, 1e-6, 0.999, 0.999], [1e-3, 2e-6, 4e-3, 1e-3], 12, 1e-3)\n",
    "        check = valid_plot(I, 1e-2)  # get rid of very abnormal scenarios\n",
    "    df = pd.DataFrame.from_dict({'time':T, 'S':S, 'I':I, 'X1':X1, 'X2':X2, 'X':X, 'Tw':Tw})\n",
    "    \n",
    "    thres = 1-20*(4e-3*param['N1'] + 1e-3*(param['N']-param['N1']))/param['N']\n",
    "    trans = transition(df['X'].groupby(np.arange(len(df['I'])) // 3).mean(), thres)\n",
    "    if trans == -1:  # ignore cases when transition has not occurred\n",
    "        continue\n",
    "    else:\n",
    "        thres_list.append(thres)\n",
    "        trans_list.append(trans)\n",
    "    \n",
    "        # interpolation for s, i, x1, x2, x\n",
    "        df_s[i] = df['S'].groupby(np.arange(len(df['S'])) // 3).mean()\n",
    "        df_i[i] = df['I'].groupby(np.arange(len(df['I'])) // 3).mean()\n",
    "        df_x1[i] = df['X1'].groupby(np.arange(len(df['X1'])) // 3).mean()\n",
    "        df_x2[i] = df['X2'].groupby(np.arange(len(df['X2'])) // 3).mean()\n",
    "        df_x[i] = df['X'].groupby(np.arange(len(df['X'])) // 3).mean()\n",
    "    \n",
    "        # aggregate for tw\n",
    "        df_tw[i] = df['Tw'].groupby(np.arange(len(df['Tw'])) // 3).sum()\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287ddece-f1fb-4d0e-b0d8-34f44f016476",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1, ax1 = plt.subplots(nrows=2, ncols=3, figsize=(15,6))\n",
    "for i, ax in zip(range(6), ax1.flatten()):\n",
    "    ax.plot(df_x.index, df_x[i], label=r'$X$', linewidth=2, color=plt.cm.Blues(128))\n",
    "    ax.set_ylim(bottom=0.95, top=1.0)\n",
    "    ax.axhline(y=thres_list[i], linestyle='--', color='k', linewidth=1)\n",
    "fig1.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c324f20-a0fe-45ed-b261-2a141e0bdf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1, ax1 = plt.subplots(nrows=2, ncols=3, figsize=(15,6))\n",
    "for i, ax in zip(range(6), ax1.flatten()):\n",
    "    ax.plot(df_tw.index, df_tw[i], label=r'$Tw$', linewidth=2, color=plt.cm.Purples(128))\n",
    "    ax.set_ylim(bottom=-1, top=50)\n",
    "    ax.set_xlim(left=trans_list[i]-600, right=trans_list[i]+100)\n",
    "    ax.axvline(x=trans_list[i]-500, linestyle='--', color='k', linewidth=1)\n",
    "    ax.axvline(x=trans_list[i], linestyle='--', color='k', linewidth=1)\n",
    "fig1.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190dbc84-6ff5-4a92-a2a4-d6ac7484c1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neutral samples\n",
    "# For the convenience of demonstration, we run a relatively small number of simulations\n",
    "# The training set contains 10000 neutral samples\n",
    "num_simu_0 = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531be825-808f-4a8b-afb2-7136ba91b935",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "while i < num_simu_0:\n",
    "    check = False\n",
    "    param = param_init()\n",
    "    while not(check):\n",
    "        T, S, I, X1, X2, X, Tw = levy_sde_media_null(param, [0.01, 1e-6, 0.999, 0.999], [1e-3, 2e-6, 4e-3, 1e-3], 12, 1e-3)\n",
    "        check = valid_plot(I, 1e-2)  # get rid of very abnormal scenarios\n",
    "    df = pd.DataFrame.from_dict({'time':T, 'S':S, 'I':I, 'X1':X1, 'X2':X2, 'X':X, 'Tw':Tw})\n",
    "    \n",
    "    thres = 1-20*(4e-3*param['N1'] + 1e-3*(param['N']-param['N1']))/param['N']\n",
    "    trans = transition(df['X'].groupby(np.arange(len(df['I'])) // 3).mean(), thres)\n",
    "    if trans != -1:  # ignore cases when transition has occurred\n",
    "        continue\n",
    "    else:\n",
    "        thres_list.append(thres)\n",
    "        trans_list.append(trans)\n",
    "    \n",
    "        # interpolation for s, i, x1, x2, x\n",
    "        j = num_simu_1 + i\n",
    "        df_s[j] = df['S'].groupby(np.arange(len(df['S'])) // 3).mean()\n",
    "        df_i[j] = df['I'].groupby(np.arange(len(df['I'])) // 3).mean()\n",
    "        df_x1[j] = df['X1'].groupby(np.arange(len(df['X1'])) // 3).mean()\n",
    "        df_x2[j] = df['X2'].groupby(np.arange(len(df['X2'])) // 3).mean()\n",
    "        df_x[j] = df['X'].groupby(np.arange(len(df['X'])) // 3).mean()\n",
    "    \n",
    "        # aggregate for tw\n",
    "        df_tw[j] = df['Tw'].groupby(np.arange(len(df['Tw'])) // 3).sum()\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017acc41-83a7-418b-816b-a3e177d42e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1, ax1 = plt.subplots(nrows=2, ncols=3, figsize=(15,6))\n",
    "for i, ax in zip(range(6), ax1.flatten()):\n",
    "    j = num_simu_1 + i\n",
    "    ax.plot(df_x.index, df_x[j], label=r'$X$', linewidth=2, color=plt.cm.Blues(128))\n",
    "    ax.set_ylim(bottom=0.95, top=1.0)\n",
    "    ax.axhline(y=thres_list[j], linestyle='--', color='k', linewidth=1)\n",
    "fig1.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4202ea6a-be65-4373-a3c7-3ce421a0f4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1, ax1 = plt.subplots(nrows=2, ncols=3, figsize=(15,6))\n",
    "for i, ax in zip(range(6), ax1.flatten()):\n",
    "    j = num_simu_1 + i\n",
    "    ax.plot(df_tw.index, df_tw[j], label=r'$Tw$', linewidth=2, color=plt.cm.Purples(128))\n",
    "    ax.set_ylim(bottom=-1, top=50)\n",
    "    ax.set_xlim(left=3500, right=4000)\n",
    "fig1.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0fad47-c623-43ae-b14a-cd5c57c50e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pt = pd.DataFrame({'thres':thres_list, 'trans':trans_list})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef65a146-e4b6-484f-a69d-24ce3880f101",
   "metadata": {},
   "source": [
    "## Code for generating training samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7203f02-9001-4f94-ae4c-1d66b84acae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables used from previous section: df_tw, df_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32964b5-29fb-4d87-8190-efdd5756cd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ts = pd.DataFrame()\n",
    "df_sm = pd.DataFrame()\n",
    "df_res = pd.DataFrame()\n",
    "lb_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad74ba6b-3ce0-401e-bde8-e065e1bf1927",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_length = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e5302a-0e29-4bea-90a1-34e6a5f43090",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(df_tw.shape[1]):\n",
    "    trans = df_pt['trans'][i]\n",
    "    \n",
    "    if trans != -1:\n",
    "        lb_list.append(1)\n",
    "        ts = ewstools.TimeSeries(data=df_tw[i], transition=trans)  # <=trans\n",
    "        \n",
    "        # Detrend\n",
    "        ts.detrend(method='Gaussian', bandwidth=100)  # 100 data points\n",
    "        df_ts[i] = ts.state[trans-ts_length:trans].reset_index()['state']  # ts_length data points before trans\n",
    "        df_sm[i] = ts.state[trans-ts_length:trans].reset_index()['smoothing']\n",
    "        res = ts.state[trans-ts_length:trans].reset_index()['residuals']\n",
    "        df_res[i] = res/np.mean(np.abs(res))  # l1-normalized\n",
    "    else:\n",
    "        lb_list.append(0)\n",
    "        ts = ewstools.TimeSeries(data=df_tw[i])  # entire time series\n",
    "        \n",
    "        # Detrend\n",
    "        ts.detrend(method='Gaussian', bandwidth=100)  # 100 data points\n",
    "        df_ts[i] = ts.state.dropna()[-ts_length:].reset_index()['state']  # last ts_length data points\n",
    "        df_sm[i] = ts.state.dropna()[-ts_length:].reset_index()['smoothing']\n",
    "        res = ts.state.dropna()[-ts_length:].reset_index()['residuals']\n",
    "        df_res[i] = res/np.mean(np.abs(res))  # l1-normalized\n",
    "\n",
    "df_lb = pd.DataFrame({'label':lb_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ab626f-880e-45b2-8161-cdba5b5d84ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1, ax1 = plt.subplots(nrows=2, ncols=3, figsize=(15,6))\n",
    "for i, ax in zip(range(6), ax1.flatten()):\n",
    "    ax.plot(df_ts.index, df_ts[i], linewidth=2, color=plt.cm.Purples(64))\n",
    "    ax.plot(df_ts.index, df_sm[i], linewidth=2, color=plt.cm.Purples(192))\n",
    "    ax.set_ylim(bottom=0, top=50)\n",
    "fig1.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b822d6d1-ea9b-452b-ae28-09197113dad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1, ax1 = plt.subplots(nrows=2, ncols=3, figsize=(15,6))\n",
    "for i, ax in zip(range(6), ax1.flatten()):\n",
    "    j = num_simu_1 + i\n",
    "    ax.plot(df_ts.index, df_ts[j], linewidth=2, color=plt.cm.Purples(64))\n",
    "    ax.plot(df_ts.index, df_sm[j], linewidth=2, color=plt.cm.Purples(192))\n",
    "    ax.set_ylim(bottom=0, top=50)\n",
    "fig1.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc20725e-b9cd-4b8c-9f06-a6c33ae248d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save file\n",
    "#df_ts.to_csv('./train_data/train_ts.csv', index=None)\n",
    "#df_sm.to_csv('./train_data/train_sm.csv', index=None)\n",
    "#df_res.to_csv('./train_data/train_res.csv', index=None)\n",
    "#df_lb.to_csv('./train_data/train_lb.csv', index=None)\n",
    "#df_pt.to_csv('./train_data/train_pt.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed41f2f-7d3a-4998-a307-2fbb8f1b820e",
   "metadata": {},
   "source": [
    "For generating testing samples, modify noise amplitudes (sigma) and repeat the above steps, or simply use part of the training set that has not been used for training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c44b34-f81c-4edc-a4c0-6f4dc3e16f3e",
   "metadata": {},
   "source": [
    "## Code for generating testing metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d20b6e-8e43-41af-928b-fc873b5a1cd7",
   "metadata": {},
   "source": [
    "Generating variance and lag-1 autocorrelation for $x$ and $T_p$ and Kendall tau for plotting ROC curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293e1200-5956-4dd6-a1cf-5484daa163bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables used from previous section: df_x, df_tw, df_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d768768-056b-4e01-8f64-39f537848bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x_ts = {}\n",
    "df_x_sm = {}\n",
    "df_x_var = {}\n",
    "df_x_ac = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd4262a-78c1-4f26-a57e-14263aa4abeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tw_ts = {}\n",
    "df_tw_sm = {}\n",
    "df_tw_var = {}\n",
    "df_tw_ac = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd95094-789d-4a77-bc4c-a518aa66e600",
   "metadata": {},
   "outputs": [],
   "source": [
    "ktau_x_dict = {'var':[], 'ac':[]}\n",
    "ktau_tw_dict = {'var':[], 'ac':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50d3b7e-3d09-4b0c-acfb-697b5232dfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(df_x.shape[1]):  # the same as df_tw.shape[1]\n",
    "    trans = df_pt['trans'][i]\n",
    "    \n",
    "    if trans != -1:\n",
    "        x_ts = ewstools.TimeSeries(data=df_x[i], transition=trans)\n",
    "        tw_ts = ewstools.TimeSeries(data=df_tw[i], transition=trans)\n",
    "    else:\n",
    "        trans = df_x.shape[0]\n",
    "        x_ts = ewstools.TimeSeries(data=df_x[i])  # entire time series\n",
    "        tw_ts = ewstools.TimeSeries(data=df_tw[i])  # entire time series\n",
    "    \n",
    "    # Detrend\n",
    "    x_ts.detrend(method='Gaussian', bandwidth=400)\n",
    "    df_x_ts[i] = x_ts.state['state']\n",
    "    df_x_sm[i] = x_ts.state['smoothing']\n",
    "    tw_ts.detrend(method='Gaussian', bandwidth=100)\n",
    "    df_tw_ts[i] = tw_ts.state['state']\n",
    "    df_tw_sm[i] = tw_ts.state['smoothing']\n",
    "    \n",
    "    # EWS\n",
    "    x_ts.compute_var(rolling_window=200)\n",
    "    x_ts.compute_auto(rolling_window=200, lag=1)\n",
    "    df_x_var[i] = x_ts.ews['variance']\n",
    "    df_x_ac[i] = x_ts.ews['ac1']\n",
    "    \n",
    "    tw_ts.compute_var(rolling_window=200)\n",
    "    tw_ts.compute_auto(rolling_window=200, lag=1)\n",
    "    df_tw_var[i] = tw_ts.ews['variance']\n",
    "    df_tw_ac[i] = tw_ts.ews['ac1']\n",
    "    \n",
    "    # Kendall tau\n",
    "    x_ts.compute_ktau(tmin=0, tmax=trans)  # tmax=trans/trans-100/trans-200/trans-400\n",
    "    ktau_x_dict['var'].append(x_ts.ktau['variance'])\n",
    "    ktau_x_dict['ac'].append(x_ts.ktau['ac1'])\n",
    "    \n",
    "    tw_ts.compute_ktau(tmin=0, tmax=trans)  # tmax=trans/trans-100/trans-200/trans-400\n",
    "    ktau_tw_dict['var'].append(tw_ts.ktau['variance'])\n",
    "    ktau_tw_dict['ac'].append(tw_ts.ktau['ac1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211ac487-f7b0-434f-a9f0-4bd222e9b1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ktau_x = pd.DataFrame(ktau_x_dict)\n",
    "df_ktau_tw = pd.DataFrame(ktau_tw_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2c8c1e-d7ed-41a4-b74f-08e5afd90519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save files\n",
    "#df_x_var.to_csv('./test_data/test_x_var.csv', index=None)\n",
    "#df_x_ac.to_csv('./test_data/test_x_ac.csv', index=None)\n",
    "#df_tw_var.to_csv('./test_data/test_tw_var.csv', index=None)\n",
    "#df_tw_ac.to_csv('./test_data/test_tw_ac.csv', index=None)\n",
    "#df_ktau_x.to_csv('./test_data/test_ktau_x.csv', index=None)\n",
    "#df_ktau_tw.to_csv('./test_data/test_ktau_tw.csv', index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
