{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b6883c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76daa71",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e53b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data from sde_simulation.ipynb\n",
    "df_res = pd.read_csv('./train_data/train_res.csv')\n",
    "df_sm = pd.read_csv('./train_data/train_sm.csv')\n",
    "df_lb = pd.read_csv('./train_data/train_lb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a04ed0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the training set\n",
    "df_res = df_res.sample(frac=1, axis=1, random_state=999)\n",
    "df_sm = df_sm.sample(frac=1, axis=1, random_state=999)\n",
    "df_lb = df_lb.sample(frac=1, random_state=999).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9121c586",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps_in, n_steps_out, n_features = 500, 1, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bc6ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_inputs(df1, df2, n_features=2):\n",
    "    # Ensure df1 and df2 are in the correct shape and convert them to NumPy arrays\n",
    "    arr1 = df1.values.T.reshape(-1, df1.shape[0], 1)  # Shape: (n_samples, n_time_steps, 1)\n",
    "    arr2 = df2.values.T.reshape(-1, df2.shape[0], 1)  # Shape: (n_samples, n_time_steps, 1)\n",
    "    \n",
    "    # Stack the arrays along the last dimension to combine the features\n",
    "    X = np.concatenate((arr1, arr2), axis=2)  # Shape: (n_samples, n_time_steps, n_features)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa4379c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_block(x, filters=50):\n",
    "    # First convolution layer\n",
    "    h = tf.keras.layers.Conv1D(filters=filters, kernel_size=8, padding='same', kernel_initializer='lecun_normal')(x)\n",
    "    h = tf.keras.layers.BatchNormalization()(h)\n",
    "    h = tf.keras.layers.Activation('relu')(h)\n",
    "    h = tf.keras.layers.Dropout(rate=0.1)(h)\n",
    "\n",
    "    # Second convolution layer\n",
    "    h = tf.keras.layers.Conv1D(filters=filters, kernel_size=5, padding='same', kernel_initializer='lecun_normal')(h)\n",
    "    h = tf.keras.layers.BatchNormalization()(h)\n",
    "    h = tf.keras.layers.Activation('relu')(h)\n",
    "    h = tf.keras.layers.Dropout(rate=0.1)(h)\n",
    "\n",
    "    # Third convolution layer\n",
    "    h = tf.keras.layers.Conv1D(filters=filters, kernel_size=3, padding='same', kernel_initializer='lecun_normal')(h)\n",
    "    h = tf.keras.layers.BatchNormalization()(h)\n",
    "    \n",
    "    # Add the shortcut (identity) to the output\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    y = tf.keras.layers.add([x, h])\n",
    "    y = tf.keras.layers.Activation('tanh')(y)\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01090294",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = reshape_inputs(df_res, df_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99453296",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131bdd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = np.array(df_lb.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee754b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d10b864",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (500,2)\n",
    "learning_rate_param = 0.0005\n",
    "batch_param = 1024\n",
    "epoch_param = 300\n",
    "initializer_param = 'lecun_normal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbf2b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "input_layer = tf.keras.layers.Input(input_shape)\n",
    "x1 = tf.keras.layers.Conv1D(filters=50, kernel_size=12, padding='same', kernel_initializer=initializer_param)(input_layer)\n",
    "y1 = residual_block(x1, filters=50)\n",
    "x2 = tf.keras.layers.Conv1D(filters=100, kernel_size=12, padding='same', kernel_initializer=initializer_param)(y1)\n",
    "y2 = residual_block(x2, filters=100)\n",
    "x3 = tf.keras.layers.Conv1D(filters=100, kernel_size=12, padding='same', kernel_initializer=initializer_param)(y2)\n",
    "y3 = residual_block(x3, filters=100)\n",
    "y = tf.keras.layers.GlobalAveragePooling1D()(y3)\n",
    "output_layer = tf.keras.layers.Dense(n_steps_out, activation='sigmoid', kernel_initializer=initializer_param)(y)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "opt = tf.keras.optimizers.legacy.Adam(learning_rate=learning_rate_param)\n",
    "model.compile(optimizer=opt, loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c354d234",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b5dce0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fit model\n",
    "model.fit(inputs, targets, epochs=epoch_param, batch_size=batch_param, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b8b592",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./trained_models/resnet_300ep_1024batch.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
